{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import traceback\n",
    "import json\n",
    "from gensim.models.word2vec import Word2Vec, Text8Corpus\n",
    "from gensim.models import KeyedVectors\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_stop_words(stop_path=\"data/stop_words_english.txt\"):\n",
    "\n",
    "    stop_words = {}\n",
    "    with open(stop_path, 'r') as fd:\n",
    "        word_list = fd.read().splitlines()\n",
    "        word_list.pop()\n",
    "        for word in word_list:\n",
    "            stop_words[word] = True\n",
    "    return stop_words\n",
    "\n",
    "\n",
    "def get_text(text_clean_path = \"data/text_clean\", text_raw_path = \"data/text8\", chunk_size=1000):\n",
    "    text = None\n",
    "    stop_words = load_stop_words()\n",
    "    # Se o dataset já existir.\n",
    "    if os.path.exists(text_clean_path):\n",
    "        with open(text_clean_path, 'r') as fd:\n",
    "            text = [fd.read().split(' ')]\n",
    "            return text\n",
    "    # Se não, pré processa ele.\n",
    "    else:\n",
    "        docs = []\n",
    "        with open(text_raw_path, 'r') as fd:\n",
    "            sentences = fd.read().split('\\n')\n",
    "            for sent in sentences:\n",
    "                clean_sent = sent.translate(str.maketrans('','', string.punctuation)).split(' ')\n",
    "                # Quebrando os documentos em chunks de 1000 palavras.\n",
    "                cont = 0\n",
    "                while cont < len(clean_sent):\n",
    "                    chunck = []\n",
    "                    # Para cada chunk.\n",
    "                    for word in clean_sent[cont : cont + chunk_size]:\n",
    "                        # Verifica se a palavra é stopword.\n",
    "                        if word not in stop_words:\n",
    "                            chunck.append(word)\n",
    "                    cont += chunk_size\n",
    "                    docs.append(chunck)\n",
    "        return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17006"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = get_text()\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(text, window, vsize, sg, min_count):\n",
    "    model_path = f\"models/window_size-{window}_vector_size-{vsize}_sg-{sg}_min_count-{min_count}\"\n",
    "    model = Word2Vec(sentences=text, vector_size=vsize, window=window, min_count=min_count, sg=sg, workers=10)\n",
    "    model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_sizes = [1,3,5,7,9,11,13,15,19,23,25]\n",
    "vector_sizes = [50, 75, 100, 150, 200, 300, 500, 1000, 2000]\n",
    "min_counts = [1, 2, 3, 5, 7, 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flag de controle para rodar os modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Mude a flag TRAIN_MODELS para true somente se quiser\n",
    "treinar os modelos.\n",
    "\"\"\"\n",
    "\n",
    "TRAIN_MODELS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_MODELS:\n",
    "    \n",
    "    # Variando o tamanho da janela.\n",
    "    for window in tqdm(window_sizes):\n",
    "        train_model(sentences, window, 100, 1, 1)\n",
    "    \n",
    "    # Variando o tamanho do vetor.\n",
    "    for vsize in tqdm(vector_sizes):\n",
    "        train_model(sentences, 5, vsize, 1, 1)\n",
    "    \n",
    "    # Variando o modelo (skip or cbow)\n",
    "    for sg in tqdm([0,1]):\n",
    "        train_model(sentences, 5, 100, sg, 1)\n",
    "    \n",
    "    # Variando o min_count.\n",
    "    for min_count in tqdm(min_counts):\n",
    "        train_model(sentences, 5, 100, 1, min_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_questions(qpath=\"data/questions-words.txt\"):\n",
    "\n",
    "    dquestions = {}\n",
    "    with open(qpath, 'r') as fd:\n",
    "        key = None\n",
    "        tests = fd.read().lower().split('\\n')\n",
    "        rest = tests.pop()\n",
    "        for test in tests:\n",
    "            categ = test[0]\n",
    "            if categ == ':':\n",
    "                dquestions[test] = []\n",
    "                key = test\n",
    "            else:\n",
    "                dquestions[key].append(test.split(' '))\n",
    "    return dquestions\n",
    "\n",
    "def are_words_in(words, model_words):\n",
    "\n",
    "    for word in words:\n",
    "        if word not in model_words.wv.key_to_index:\n",
    "            print(f\"{word} does not exist\")\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "def ranking_words_most_similar(words, model, topn=5):\n",
    "    \n",
    "    try:\n",
    "        w1, w2, w3, _ = words\n",
    "        return list(model.wv.most_similar(positive=[w1, w3], negative=[w2], topn=topn))\n",
    "    except Exception as err:\n",
    "        return []\n",
    "\n",
    "\n",
    "def evaluate_model(dquestions, model, topn=5):\n",
    "    \n",
    "    score_categ = {}\n",
    "    number_exceptions = 0\n",
    "    # Para cada categoria de teste.\n",
    "    for categ in dquestions:\n",
    "        hits = 0\n",
    "        misses = 0\n",
    "        close_to = 0\n",
    "        score = 0\n",
    "        score_categ[categ] = {}\n",
    "        # Para cada test.\n",
    "        for test in dquestions[categ]:\n",
    "            target = test[-1]\n",
    "            ranking = ranking_words_most_similar(test, model, topn=topn)\n",
    "            if ranking:\n",
    "                #random_word = np.random.randint(len(ranking))\n",
    "                #target = ranking[random_word][0]\n",
    "                #if np.random.randint(2) == 0:\n",
    "                #    target = test[-1]\n",
    "                first_word = ranking.pop(0)\n",
    "                # Verificando se a primeira palavra é o target esperado.\n",
    "                if first_word[0] == target:\n",
    "                    hits += 1\n",
    "                    score += first_word[1]\n",
    "                # Se não verifique se a palavra está no ranking.\n",
    "                else:\n",
    "                    rwords = [w[0] for w in ranking ]\n",
    "                    if target in rwords:\n",
    "                        close_to += 1\n",
    "                        distance = rwords.index(target) + 1\n",
    "                        score += (1 / distance) * ranking[distance - 1][1]\n",
    "                    else:\n",
    "                        misses += 1\n",
    "            else:\n",
    "                number_exceptions +=1\n",
    "        score_categ[categ][\"hits\"] = hits\n",
    "        score_categ[categ][\"misses\"] = misses\n",
    "        score_categ[categ][\"close_to\"] = close_to\n",
    "        score_categ[categ][\"score\"] = score\n",
    "    print(f\"Exceptions: {number_exceptions}\")\n",
    "    return score_categ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: window_size-5_vector_size-2000_sg-1_min_count-1\n",
      "Exceptions: 2878\n",
      "\n",
      "Model: window_size-5_vector_size-100_sg-1_min_count-2\n",
      "Exceptions: 3195\n",
      "\n",
      "Model: window_size-5_vector_size-50_sg-1_min_count-1\n",
      "Exceptions: 2878\n",
      "\n",
      "Model: window_size-5_vector_size-1000_sg-1_min_count-1\n",
      "Exceptions: 2878\n",
      "\n",
      "Model: window_size-5_vector_size-100_sg-0_min_count-1\n",
      "Exceptions: 2878\n",
      "\n",
      "Model: window_size-25_vector_size-100_sg-1_min_count-1\n",
      "Exceptions: 2878\n",
      "\n",
      "Model: window_size-15_vector_size-100_sg-1_min_count-1\n",
      "Exceptions: 2878\n",
      "\n",
      "Model: window_size-5_vector_size-200_sg-1_min_count-1\n",
      "Exceptions: 2878\n",
      "\n",
      "Model: window_size-5_vector_size-100_sg-1_min_count-10\n",
      "Exceptions: 5562\n",
      "\n",
      "Model: window_size-3_vector_size-100_sg-1_min_count-1\n",
      "Exceptions: 2878\n",
      "\n",
      "Model: window_size-5_vector_size-100_sg-1_min_count-7\n",
      "Exceptions: 4698\n",
      "\n",
      "Model: window_size-5_vector_size-500_sg-1_min_count-1\n",
      "Exceptions: 2878\n",
      "\n",
      "Model: window_size-7_vector_size-100_sg-1_min_count-1\n",
      "Exceptions: 2878\n",
      "\n",
      "Model: window_size-5_vector_size-75_sg-1_min_count-1\n",
      "Exceptions: 2878\n",
      "\n",
      "Model: window_size-13_vector_size-100_sg-1_min_count-1\n",
      "Exceptions: 2878\n",
      "\n",
      "Model: window_size-5_vector_size-150_sg-1_min_count-1\n",
      "Exceptions: 2878\n",
      "\n",
      "Model: window_size-9_vector_size-100_sg-1_min_count-1\n",
      "Exceptions: 2878\n",
      "\n",
      "Model: window_size-11_vector_size-100_sg-1_min_count-1\n",
      "Exceptions: 2878\n",
      "\n",
      "Model: window_size-5_vector_size-100_sg-1_min_count-5\n",
      "Exceptions: 3932\n",
      "\n",
      "Model: window_size-1_vector_size-100_sg-1_min_count-1\n",
      "Exceptions: 2878\n",
      "\n",
      "Model: window_size-19_vector_size-100_sg-1_min_count-1\n",
      "Exceptions: 2878\n",
      "\n",
      "Model: window_size-5_vector_size-100_sg-1_min_count-3\n",
      "Exceptions: 3659\n",
      "\n",
      "Model: window_size-5_vector_size-300_sg-1_min_count-1\n",
      "Exceptions: 2878\n",
      "\n",
      "Model: window_size-5_vector_size-100_sg-1_min_count-1\n",
      "Exceptions: 2878\n",
      "\n",
      "Model: window_size-23_vector_size-100_sg-1_min_count-1\n",
      "Exceptions: 2878\n"
     ]
    }
   ],
   "source": [
    "dquestions = prep_questions()\n",
    "#models_paths = np.random.choice([ f for f in os.listdir(\"models/\") if f.find(\"npy\") == -1 ], 3)\n",
    "models_paths = [ f for f in os.listdir(\"models/\") if f.find(\"npy\") == -1 ]\n",
    "models_score = {}\n",
    "for f in models_paths:\n",
    "    print(f\"\\nModel: {f}\")\n",
    "    model = KeyedVectors.load(f\"models/{f}\")\n",
    "    models_score[f] = evaluate_model(dquestions, model)\n",
    "    output = f\"outputs/models/{f}.json\"\n",
    "    with open(output, 'w') as fd:\n",
    "        json.dump(models_score[f], fd, indent=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3a42a9c5247d45854756dcdfa5bcaf448c71a6cb5a74d180ad5b016b0912211a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit ('.env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
